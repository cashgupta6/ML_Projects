# -*- coding: utf-8 -*-
"""kaggle.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wLR3EGV30o4HYiskVgCEZN9C1F48Lq12
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pandas.plotting import scatter_matrix
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
from sklearn.externals import joblib
import seaborn as sns
from sklearn.cluster import KMeans

# %matplotlib inline

df = pd.read_csv('/content/drive/MyDrive/KmeansClustering_customer_segmentation/data.csv')
df

df.info()

df.describe()

X = df.iloc[:,[3,4]].values

"""Calculating WCSS = Within-Cluster-Sum-of-Squares """

wcss = []
for i in range(1,11):
  kmeans = KMeans(n_clusters=i,init = 'k-means++')
  kmeans.fit(X)
  wcss.append(kmeans.inertia_)

"""Plotting Elbow graph"""

plt.plot(range(1,11),wcss)
plt.title('The Elbow point graph')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')

"""Number of cluster to be made is 5"""

kmeans = KMeans(n_clusters=5,init = 'k-means++')
Y = kmeans.fit_predict(X)
df2 = pd.DataFrame(Y)

"""Givving the numerical attribute to each cluster"""

kmeans = KMeans(n_clusters=5, init='k-means++', random_state=0)

# return a label for each data point based on their cluster
Y = kmeans.fit_predict(X)

print(Y)

"""Plotting all clusters"""

plt.figure(figsize=(8,8))
plt.scatter(X[Y==0,0], X[Y==0,1], s=50, c='green', label='Cluster 1')
plt.scatter(X[Y==1,0], X[Y==1,1], s=50, c='red', label='Cluster 2')
plt.scatter(X[Y==2,0], X[Y==2,1], s=50, c='yellow', label='Cluster 3')
plt.scatter(X[Y==3,0], X[Y==3,1], s=50, c='violet', label='Cluster 4')
plt.scatter(X[Y==4,0], X[Y==4,1], s=50, c='blue', label='Cluster 5')

# plot the centroids
plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=100, c='cyan', label='Centroids')

plt.title('Customer Groups')
plt.xlabel('Annual Income')
plt.ylabel('Spending Score')
plt.show()

"""Concating the cluster values with original dataframe"""

df1 = pd.DataFrame(Y)
df2 = pd.concat([df, df1.reindex(df.index)], axis=1)

df2.isna().sum()

df2 = df2.rename(columns={0: 'cluster_number'})

"""Converting categorical data to numerical data"""

df2 = df2.replace({'Male': 0, 'Female': 1})

df2.head()

"""Getting X and Y attributes for training the model"""

x = df2.drop(columns = ['CustomerID','cluster_number'])
y = df2['cluster_number']

"""Splitting attributes into training and testing dataset"""

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3)

len(x_test)

"""Function to check best model for training the dataset"""

def check(model):
  score = 0
  for model in model:
    model.fit(x_train,y_train)
    model_name = type(model).__name__
    temp_score = model.score(x_test,y_test)
    if temp_score>score:
      score = temp_score
      model_name_best = model_name
      model_final = model
    print(model_name,temp_score)
    print('\n')
  print('The best model is : ',model_name_best,score)
  print('\n')
  return model_final

"""Input model Array and Getting result"""

model = [LinearRegression(),LogisticRegression(), SVC(), DecisionTreeClassifier(), Lasso(),Ridge()]
model = check(model)

"""Tesing the predicted value of model with Actual value"""

df.result = df2.cluster_number
arr = [1,23,16,77]

input = np.array(arr)
predicted = model.predict([input])[0]
Actual = df.result.iloc[3]
print('The Predicted value is: ', predicted)
print('The Actual value is: ', Actual)

cd /content/drive/MyDrive/KmeansClustering_customer_segmentation

joblib.dump(model, 'model.pkl')